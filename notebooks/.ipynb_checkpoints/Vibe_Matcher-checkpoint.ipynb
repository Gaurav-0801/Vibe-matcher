{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Vibe Matcher: Mini Recommender Prototype\n",
        "\n",
        "AI can augment Nexora's product discovery by matching a shopper's vibe (free-text intent) to items whose descriptions and style tags semantically align. This notebook builds a compact pipeline: mock catalog → OpenAI embeddings → cosine similarity search → quick evaluation and latency plot. It’s intentionally small, explainable, and fast to iterate, yet extensible to vector DBs and better re-ranking later.\n",
        "\n",
        "---\n",
        "\n",
        "## Sections\n",
        "1. Setup\n",
        "2. Data Prep\n",
        "3. Embeddings\n",
        "4. Vector Search\n",
        "5. Test & Eval\n",
        "6. Metrics & Plot\n",
        "7. Reflection\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup\n",
        "!pip -q install openai pandas numpy scikit-learn matplotlib python-dotenv tenacity\n",
        "\n",
        "import os, time, json\n",
        "from dataclasses import dataclass\n",
        "from typing import List, Dict, Any\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from tenacity import retry, wait_exponential, stop_after_attempt\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "try:\n",
        "    from openai import OpenAI\n",
        "    client = OpenAI()\n",
        "except Exception:\n",
        "    client = None\n",
        "    import openai  # legacy fallback\n",
        "\n",
        "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
        "if not OPENAI_API_KEY and client is None:\n",
        "    print(\"Set OPENAI_API_KEY in environment before running embedding cells.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Data Prep: mock catalog (5–10 items)\n",
        "\n",
        "@dataclass\n",
        "class Product:\n",
        "    name: str\n",
        "    vibes: List[str]\n",
        "    price: float\n",
        "    desc: str\n",
        "\n",
        "def build_catalog() -> List[Product]:\n",
        "    return [\n",
        "        Product(\"Boho Festival Dress\", [\"boho\",\"cozy\",\"festival\",\"earthy\"], 89.99,\n",
        "                \"Flowy, earthy tones, relaxed silhouette for outdoor festivals.\"),\n",
        "        Product(\"Urban Sleek Blazer\", [\"urban\",\"professional\",\"minimalist\",\"edgy\"], 159.99,\n",
        "                \"Tailored city blazer with sharp lines for modern professionals.\"),\n",
        "        Product(\"Vintage Leather Jacket\", [\"edgy\",\"vintage\",\"rebellious\",\"cool\"], 249.99,\n",
        "                \"Classic leather with worn-in finish; bold and timeless.\"),\n",
        "        Product(\"Cozy Oversized Sweater\", [\"cozy\",\"comfort\",\"casual\",\"warm\"], 74.99,\n",
        "                \"Soft oversized knit for lounging and everyday comfort.\"),\n",
        "        Product(\"Neon Cyber Bodysuit\", [\"energetic\",\"urban\",\"futuristic\",\"bold\"], 129.99,\n",
        "                \"High-impact neon accents; nightlife-ready futuristic vibe.\"),\n",
        "        Product(\"Romantic Lace Gown\", [\"romantic\",\"elegant\",\"sophisticated\",\"feminine\"], 349.99,\n",
        "                \"Graceful lace detailing for formal occasions.\"),\n",
        "        Product(\"Eco-Conscious Linen Pants\", [\"sustainable\",\"minimal\",\"eco\",\"conscious\"], 94.99,\n",
        "                \"Breathable linen, ethically produced with sustainable materials.\"),\n",
        "        Product(\"Glam Sequin Tank\", [\"glam\",\"party\",\"sparkly\",\"celebratory\"], 64.99,\n",
        "                \"Shimmering sequins for party looks.\"),\n",
        "        Product(\"Sporty Athleisure Set\", [\"sporty\",\"active\",\"casual\",\"confident\"], 119.99,\n",
        "                \"Performance fabric for gym-to-street versatility.\"),\n",
        "        Product(\"Avant-Garde Experimental Jacket\", [\"experimental\",\"artistic\",\"bold\",\"creative\"], 299.99,\n",
        "                \"Sculptural statement piece with unconventional design.\"),\n",
        "    ]\n",
        "\n",
        "products = build_catalog()\n",
        "\n",
        "def product_text(p: Product) -> str:\n",
        "    return \" \".join([p.name, \" \".join(p.vibes), p.desc])\n",
        "\n",
        "df = pd.DataFrame([\n",
        "    {\"name\": p.name, \"vibes\": p.vibes, \"price\": p.price, \"desc\": p.desc, \"text\": product_text(p)}\n",
        "    for p in products\n",
        "])\n",
        "\n",
        "df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Embeddings: OpenAI (text-embedding-3-small by default)\n",
        "EMBED_MODEL = os.getenv(\"EMBED_MODEL\", \"text-embedding-3-small\")  # or \"text-embedding-ada-002\"\n",
        "\n",
        "\n",
        "def _embed_batch_openai(texts: List[str]) -> List[List[float]]:\n",
        "    if client is not None:\n",
        "        resp = client.embeddings.create(model=EMBED_MODEL, input=texts)\n",
        "        return [d.embedding for d in resp.data]\n",
        "    else:\n",
        "        import openai\n",
        "        openai.api_key = OPENAI_API_KEY\n",
        "        resp = openai.Embedding.create(model=EMBED_MODEL, input=texts)\n",
        "        return [d[\"embedding\"] for d in resp[\"data\"]]\n",
        "\n",
        "\n",
        "@retry(wait=wait_exponential(multiplier=1, min=1, max=20), stop=stop_after_attempt(5))\n",
        "def embed_texts(texts: List[str], batch_size: int = 64) -> List[List[float]]:\n",
        "    out: List[List[float]] = []\n",
        "    for i in range(0, len(texts), batch_size):\n",
        "        out.extend(_embed_batch_openai(texts[i:i+batch_size]))\n",
        "    return out\n",
        "\n",
        "if not OPENAI_API_KEY and client is None:\n",
        "    raise RuntimeError(\"Missing OPENAI_API_KEY; set it before running.\")\n",
        "\n",
        "print(\"Embedding products...\")\n",
        "prod_embeddings = embed_texts(df[\"text\"].tolist())\n",
        "emb_dim = len(prod_embeddings[0]) if prod_embeddings else 0\n",
        "print(f\"\\u2713 Embedded {len(prod_embeddings)} products | dim={emb_dim}\")\n",
        "\n",
        "prod_matrix = np.array(prod_embeddings, dtype=np.float32)\n",
        "prod_matrix.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Vector Search: cosine top-3 with fallback\n",
        "\n",
        "def search(query: str, top_k: int = 3, no_match_threshold: float = 0.15) -> Dict[str, Any]:\n",
        "    q_emb = np.array(embed_texts([query])[0], dtype=np.float32)[None, :]\n",
        "    sims = cosine_similarity(q_emb, prod_matrix)[0]\n",
        "    idx = np.argsort(-sims)[:top_k]\n",
        "    results = []\n",
        "    for rank, i in enumerate(idx, start=1):\n",
        "        row = df.iloc[i]\n",
        "        results.append({\n",
        "            \"rank\": rank,\n",
        "            \"name\": row[\"name\"],\n",
        "            \"price\": float(row[\"price\"]),\n",
        "            \"vibes\": row[\"vibes\"],\n",
        "            \"similarity\": float(sims[i]),\n",
        "        })\n",
        "    max_sim = float(sims[idx[0]]) if len(idx) else 0.0\n",
        "    fallback = None\n",
        "    if max_sim < no_match_threshold:\n",
        "        fallback = (\"No strong matches found. Refine with 2–4 vibes (e.g., 'minimalist, eco'), \"\n",
        "                    \"an occasion ('work', 'festival'), or fit preference.\")\n",
        "    return {\"query\": query, \"results\": results, \"max_similarity\": max_sim, \"fallback\": fallback}\n",
        "\n",
        "# Demo query\n",
        "_demo = search(\"futuristic urban party outfit\", top_k=3)\n",
        "_demo\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Pretty print helper with bands\n",
        "\n",
        "def band(score: float) -> str:\n",
        "    return \"HIGH\" if score >= 0.7 else (\"MODERATE\" if score >= 0.5 else \"LOW\")\n",
        "\n",
        "def print_results(result: Dict[str, Any]) -> None:\n",
        "    print(result[\"query\"]) \n",
        "    print(\"-\" * 70)\n",
        "    for r in result[\"results\"]:\n",
        "        print(f\"  #{r['rank']} {r['name']} (${r['price']})\")\n",
        "        print(f\"      Similarity: {r['similarity']:.4f} | {band(r['similarity'])}\")\n",
        "        print(f\"      Vibes: {', '.join(r['vibes'])}\")\n",
        "    if result[\"fallback\"]:\n",
        "        print(f\"  Fallback: {result['fallback']}\")\n",
        "    print()\n",
        "\n",
        "print_results(_demo)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test & Eval: 3 queries, metrics and timings\n",
        "\n",
        "test_queries = [\n",
        "    \"I want bold, energetic urban nightlife fashion\",\n",
        "    \"Looking for cozy, comfortable everyday wear\",\n",
        "    \"Seeking sustainable, eco-conscious ethical fashion\",\n",
        "]\n",
        "\n",
        "good_threshold = 0.7\n",
        "latencies = []\n",
        "records = []\n",
        "\n",
        "for i, q in enumerate(test_queries, start=1):\n",
        "    t0 = time.perf_counter()\n",
        "    out = search(q, top_k=3)\n",
        "    t1 = time.perf_counter()\n",
        "    lat = t1 - t0\n",
        "    latencies.append(lat)\n",
        "\n",
        "    print_results(out)\n",
        "\n",
        "    scores = [r[\"similarity\"] for r in out[\"results\"]]\n",
        "    top1 = scores[0] if scores else 0.0\n",
        "    avg_top3 = float(np.mean(scores)) if scores else 0.0\n",
        "    quality = \"good\" if top1 >= good_threshold else \"not_good\"\n",
        "\n",
        "    rec = {\n",
        "        \"query_index\": i,\n",
        "        \"query\": q,\n",
        "        \"top1_similarity\": round(top1, 4),\n",
        "        \"avg_top3_similarity\": round(avg_top3, 4),\n",
        "        \"quality\": quality,\n",
        "        \"latency_sec\": round(lat, 4),\n",
        "        \"fallback_triggered\": out[\"fallback\"] is not None,\n",
        "        \"top_3\": out[\"results\"],\n",
        "    }\n",
        "    records.append(rec)\n",
        "\n",
        "len(records), len(latencies)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> Colab note: If running in Colab, run the Setup cell first to install dependencies. Then set the `OPENAI_API_KEY` in the session environment before executing the Embeddings cell.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Metrics: JSONL logging and latency plot\n",
        "import os\n",
        "os.makedirs(\"logs\", exist_ok=True)\n",
        "log_path = \"logs/vibe_matcher_metrics.jsonl\"\n",
        "with open(log_path, \"w\", encoding=\"utf-8\") as f:\n",
        "    for r in records:\n",
        "        f.write(json.dumps(r) + \"\\n\")\n",
        "print(f\"\\u2713 Logged metrics to {log_path}\")\n",
        "\n",
        "plt.figure(figsize=(7,4))\n",
        "plt.plot(range(1, len(latencies)+1), latencies, marker=\"o\")\n",
        "plt.title(\"Vector Search Latency per Query\")\n",
        "plt.xlabel(\"Query #\")\n",
        "plt.ylabel(\"Latency (s)\")\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"vibe_matcher_latency.png\", dpi=150)\n",
        "print(\"\\u2713 Saved latency plot to vibe_matcher_latency.png\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Reflection: 3–5 bullets and optional txt\n",
        "reflection = [\n",
        "    \"- Improvements: integrate a vector DB (Pinecone/FAISS) for ANN; re-rank top-10 with a cross-encoder; cache embeddings.\",\n",
        "    \"- Edge cases: empty/very short queries trigger fallback; small catalog; ties; multilingual queries (model support varies).\",\n",
        "    \"- Metrics: explicit 'good' threshold (>=0.7), JSONL logs; extend with P95 latency and success@k over larger sets.\",\n",
        "    \"- Productization: add filters (price/occasion), tracking, and A/B thresholds by intent.\",\n",
        "    \"- Ops: switch to 'text-embedding-3-large' for quality-sensitive flows; cost-optimize with caching.\",\n",
        "]\n",
        "print(\"Reflection\\n\" + \"\\n\".join(reflection))\n",
        "\n",
        "with open(\"vibe_matcher_reflection.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(\"Reflection\\n\" + \"\\n\".join(reflection))\n",
        "print(\"\\u2713 Saved reflection to vibe_matcher_reflection.txt\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
